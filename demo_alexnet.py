"""
AlexNetå¿«é€Ÿæ¼”ç¤ºè„šæœ¬
å±•ç¤ºæ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°çš„å®Œæ•´æµç¨‹
"""

import os
import sys
import torch
import logging
from tqdm import tqdm

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def demo_alexnet():
    """AlexNetæ¼”ç¤ºå‡½æ•°"""
    
    # å¯¼å…¥é¡¹ç›®æ¨¡å—
    from models.alexnet import create_alexnet
    from datasets.cifar import CIFAR10Dataset
    from configs.alexnet_config import AlexNetConfig
    from utils.device import get_best_device, optimize_for_device
    from utils.metrics import calculate_accuracy
    
    logger.info("ğŸš€ å¼€å§‹AlexNetæ¼”ç¤º...")
    
    # è·å–è®¾å¤‡
    device = get_best_device()
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ›å»ºé…ç½®
    config = AlexNetConfig()
    config.epochs = 2  # åªè®­ç»ƒ2ä¸ªepochç”¨äºæ¼”ç¤º
    config.batch_size = 16
    config.num_workers = 0  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
    
    # åˆ›å»ºæ¨¡å‹
    logger.info("ğŸ“¦ åˆ›å»ºAlexNetæ¨¡å‹...")
    model_config = config.get_alexnet_config()
    model = create_alexnet(**model_config)
    model = optimize_for_device(model, device)
    
    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    logger.info(f"æ¨¡å‹å‚æ•°æ•°é‡: {model.count_parameters():,}")
    logger.info(f"æ¨¡å‹å¤§å°: {model.get_model_size_mb():.2f} MB")
    
    # åˆ›å»ºæ•°æ®é›†
    logger.info("ğŸ“Š åŠ è½½CIFAR-10æ•°æ®é›†...")
    data_config = config.get_data_config()
    data_config['num_workers'] = 0
    dataset = CIFAR10Dataset(**data_config)
    train_loader, test_loader = dataset.get_dataloaders()
    
    # è®¾ç½®è®­ç»ƒç»„ä»¶
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    criterion = torch.nn.CrossEntropyLoss()
    
    # è®­ç»ƒå¾ªç¯
    logger.info("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
    model.train()
    
    for epoch in range(config.epochs):
        total_loss = 0
        total_correct = 0
        total_samples = 0
        
        progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{config.epochs}')
        
        for batch_idx, (data, target) in enumerate(progress_bar):
            data, target = data.to(device), target.to(device)
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            
            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            total_correct += calculate_accuracy(output, target) * target.size(0)
            total_samples += target.size(0)
            
            # æ›´æ–°è¿›åº¦æ¡
            if batch_idx % 100 == 0:
                progress_bar.set_postfix({
                    'Loss': f'{loss.item():.4f}',
                    'Acc': f'{calculate_accuracy(output, target):.2%}'
                })
        
        # è®¡ç®—epochç»Ÿè®¡
        avg_loss = total_loss / len(train_loader)
        avg_accuracy = total_correct / total_samples
        
        logger.info(f'Epoch {epoch+1}: Loss: {avg_loss:.4f}, Accuracy: {avg_accuracy:.2%}')
    
    # è¯„ä¼°æ¨¡å‹
    logger.info("ğŸ” è¯„ä¼°æ¨¡å‹...")
    model.eval()
    total_correct = 0
    total_samples = 0
    
    with torch.no_grad():
        for data, target in tqdm(test_loader, desc='Evaluating'):
            data, target = data.to(device), target.to(device)
            output = model(data)
            total_correct += calculate_accuracy(output, target) * target.size(0)
            total_samples += target.size(0)
    
    test_accuracy = total_correct / total_samples
    logger.info(f"æµ‹è¯•å‡†ç¡®ç‡: {test_accuracy:.2%}")
    
    # å•å¼ å›¾åƒé¢„æµ‹æ¼”ç¤º
    logger.info("ğŸ–¼ï¸ å•å¼ å›¾åƒé¢„æµ‹æ¼”ç¤º...")
    model.eval()
    
    # è·å–ä¸€å¼ æµ‹è¯•å›¾åƒ
    for data, target in test_loader:
        sample_image = data[0:1].to(device)
        sample_target = target[0]
        break
    
    with torch.no_grad():
        output = model(sample_image)
        probabilities = torch.softmax(output, dim=1)
        predicted_class = torch.argmax(output, dim=1).item()
        confidence = probabilities[0][predicted_class].item()
    
    class_names = dataset.get_class_names()
    predicted_class_name = class_names[predicted_class]
    true_class_name = class_names[sample_target.item()]
    
    logger.info(f"é¢„æµ‹ç±»åˆ«: {predicted_class_name} (ç½®ä¿¡åº¦: {confidence:.2%})")
    logger.info(f"çœŸå®ç±»åˆ«: {true_class_name}")
    
    logger.info("âœ… AlexNetæ¼”ç¤ºå®Œæˆï¼")
    
    return {
        'device': str(device),
        'model_params': model.count_parameters(),
        'model_size_mb': model.get_model_size_mb(),
        'test_accuracy': test_accuracy,
        'predicted_class': predicted_class_name,
        'true_class': true_class_name,
        'confidence': confidence
    }

if __name__ == '__main__':
    # ç¡®ä¿åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"MPSå¯ç”¨: {torch.backends.mps.is_available()}")
        
        results = demo_alexnet()
        
        print("\n" + "="*50)
        print("æ¼”ç¤ºç»“æœæ‘˜è¦:")
        print("="*50)
        for key, value in results.items():
            print(f"{key}: {value}")
        print("="*50)
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å·²æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…äº†æ‰€æœ‰ä¾èµ–")
        print("è¿è¡Œ: source venv/bin/activate && pip install -r requirements.txt")
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
