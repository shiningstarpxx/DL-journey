"""
æ¨¡å‹å¯¹æ¯”è„šæœ¬
åŒæ—¶è®­ç»ƒAlexNetå’ŒLeNetï¼Œå¯¹æ¯”å®ƒä»¬åœ¨CIFAR-10æ•°æ®é›†ä¸Šçš„æ€§èƒ½
"""

import os
import sys
import torch
import logging
import time
import json
from tqdm import tqdm
import matplotlib.pyplot as plt
import numpy as np

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ModelComparison:
    """æ¨¡å‹å¯¹æ¯”ç±»"""
    
    def __init__(self):
        # å¯¼å…¥é¡¹ç›®æ¨¡å—
        from models.alexnet import create_alexnet
        from models.lenet import create_lenet
        from datasets.cifar import CIFAR10Dataset
        from utils.device import get_best_device, optimize_for_device
        from utils.metrics import calculate_accuracy
        
        # ä¿å­˜å¯¼å…¥çš„å‡½æ•°
        self.calculate_accuracy = calculate_accuracy
        
        self.device = get_best_device()
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}")
        
        # åˆ›å»ºæ•°æ®é›†
        logger.info("ğŸ“Š åŠ è½½CIFAR-10æ•°æ®é›†...")
        self.dataset = CIFAR10Dataset(batch_size=32, num_workers=0)
        self.train_loader, self.test_loader = self.dataset.get_dataloaders()
        
        # åˆ›å»ºæ¨¡å‹
        logger.info("ğŸ“¦ åˆ›å»ºæ¨¡å‹...")
        self.alexnet = create_alexnet(num_classes=10, modern=True)
        self.alexnet = optimize_for_device(self.alexnet, self.device)
        
        self.lenet = create_lenet(num_classes=10, modern=True, input_channels=3)
        self.lenet = optimize_for_device(self.lenet, self.device)
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        logger.info(f"AlexNetå‚æ•°æ•°é‡: {self.alexnet.count_parameters():,}")
        logger.info(f"LeNetå‚æ•°æ•°é‡: {self.lenet.count_parameters():,}")
        logger.info(f"AlexNetæ¨¡å‹å¤§å°: {self.alexnet.get_model_size_mb():.2f} MB")
        logger.info(f"LeNetæ¨¡å‹å¤§å°: {self.lenet.get_model_size_mb():.2f} MB")
        
        # è®­ç»ƒé…ç½®
        self.epochs = 5  # å¯¹æ¯”è®­ç»ƒ5ä¸ªepoch
        self.learning_rate = 0.001
        
        # å­˜å‚¨è®­ç»ƒå†å²
        self.history = {
            'alexnet': {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []},
            'lenet': {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
        }
    
    def train_model(self, model, model_name):
        """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
        logger.info(f"ğŸ¯ å¼€å§‹è®­ç»ƒ {model_name}...")
        
        optimizer = torch.optim.Adam(model.parameters(), lr=self.learning_rate)
        criterion = torch.nn.CrossEntropyLoss()
        
        train_losses = []
        train_accs = []
        val_losses = []
        val_accs = []
        
        for epoch in range(self.epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            total_loss = 0
            total_correct = 0
            total_samples = 0
            
            progress_bar = tqdm(self.train_loader, desc=f'{model_name} Epoch {epoch+1}/{self.epochs}')
            
            for data, target in progress_bar:
                data, target = data.to(self.device), target.to(self.device)
                
                optimizer.zero_grad()
                output = model(data)
                loss = criterion(output, target)
                loss.backward()
                optimizer.step()
                
                total_loss += loss.item()
                total_correct += self.calculate_accuracy(output, target) * target.size(0)
                total_samples += target.size(0)
                
                if len(progress_bar) % 100 == 0:
                    progress_bar.set_postfix({
                        'Loss': f'{loss.item():.4f}',
                        'Acc': f'{self.calculate_accuracy(output, target):.2%}'
                    })
            
            avg_train_loss = total_loss / len(self.train_loader)
            avg_train_acc = total_correct / total_samples
            train_losses.append(avg_train_loss)
            train_accs.append(avg_train_acc)
            
            # éªŒè¯é˜¶æ®µ
            model.eval()
            total_val_loss = 0
            total_val_correct = 0
            total_val_samples = 0
            
            with torch.no_grad():
                for data, target in self.test_loader:
                    data, target = data.to(self.device), target.to(self.device)
                    output = model(data)
                    loss = criterion(output, target)
                    
                    total_val_loss += loss.item()
                    total_val_correct += self.calculate_accuracy(output, target) * target.size(0)
                    total_val_samples += target.size(0)
            
            avg_val_loss = total_val_loss / len(self.test_loader)
            avg_val_acc = total_val_correct / total_val_samples
            val_losses.append(avg_val_loss)
            val_accs.append(avg_val_acc)
            
            logger.info(f'{model_name} Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc:.2%}, Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc:.2%}')
        
        return train_losses, train_accs, val_losses, val_accs
    
    def compare_models(self):
        """å¯¹æ¯”æ¨¡å‹æ€§èƒ½"""
        logger.info("ğŸš€ å¼€å§‹æ¨¡å‹å¯¹æ¯”...")
        
        # è®­ç»ƒAlexNet
        alexnet_train_loss, alexnet_train_acc, alexnet_val_loss, alexnet_val_acc = self.train_model(self.alexnet, "AlexNet")
        
        # è®­ç»ƒLeNet
        lenet_train_loss, lenet_train_acc, lenet_val_loss, lenet_val_acc = self.train_model(self.lenet, "LeNet")
        
        # å­˜å‚¨ç»“æœ
        self.history['alexnet']['train_loss'] = alexnet_train_loss
        self.history['alexnet']['train_acc'] = alexnet_train_acc
        self.history['alexnet']['val_loss'] = alexnet_val_loss
        self.history['alexnet']['val_acc'] = alexnet_val_acc
        
        self.history['lenet']['train_loss'] = lenet_train_loss
        self.history['lenet']['train_acc'] = lenet_train_acc
        self.history['lenet']['val_loss'] = lenet_val_loss
        self.history['lenet']['val_acc'] = lenet_val_acc
        
        # æœ€ç»ˆè¯„ä¼°
        self.final_evaluation()
        
        # ç»˜åˆ¶å¯¹æ¯”å›¾
        self.plot_comparison()
        
        # ä¿å­˜ç»“æœ
        self.save_results()
    
    def final_evaluation(self):
        """æœ€ç»ˆè¯„ä¼°"""
        logger.info("ğŸ” æœ€ç»ˆè¯„ä¼°...")
        
        results = {}
        
        for model_name, model in [('AlexNet', self.alexnet), ('LeNet', self.lenet)]:
            model.eval()
            total_correct = 0
            total_samples = 0
            inference_times = []
            
            with torch.no_grad():
                for data, target in tqdm(self.test_loader, desc=f'Evaluating {model_name}'):
                    data, target = data.to(self.device), target.to(self.device)
                    
                    # æµ‹é‡æ¨ç†æ—¶é—´
                    start_time = time.time()
                    output = model(data)
                    inference_time = time.time() - start_time
                    inference_times.append(inference_time)
                    
                    total_correct += self.calculate_accuracy(output, target) * target.size(0)
                    total_samples += target.size(0)
            
            accuracy = total_correct / total_samples
            avg_inference_time = np.mean(inference_times)
            
            results[model_name] = {
                'final_accuracy': accuracy,
                'avg_inference_time': avg_inference_time,
                'model_params': model.count_parameters(),
                'model_size_mb': model.get_model_size_mb()
            }
            
            logger.info(f"{model_name} - æœ€ç»ˆå‡†ç¡®ç‡: {accuracy:.2%}, å¹³å‡æ¨ç†æ—¶é—´: {avg_inference_time:.4f}s")
        
        self.final_results = results
    
    def plot_comparison(self):
        """ç»˜åˆ¶å¯¹æ¯”å›¾"""
        logger.info("ğŸ“Š ç»˜åˆ¶å¯¹æ¯”å›¾...")
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        epochs = range(1, self.epochs + 1)
        
        # è®­ç»ƒæŸå¤±å¯¹æ¯”
        ax1.plot(epochs, self.history['alexnet']['train_loss'], 'b-', label='AlexNet', linewidth=2)
        ax1.plot(epochs, self.history['lenet']['train_loss'], 'r-', label='LeNet', linewidth=2)
        ax1.set_title('è®­ç»ƒæŸå¤±å¯¹æ¯”')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True)
        
        # è®­ç»ƒå‡†ç¡®ç‡å¯¹æ¯”
        ax2.plot(epochs, self.history['alexnet']['train_acc'], 'b-', label='AlexNet', linewidth=2)
        ax2.plot(epochs, self.history['lenet']['train_acc'], 'r-', label='LeNet', linewidth=2)
        ax2.set_title('è®­ç»ƒå‡†ç¡®ç‡å¯¹æ¯”')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True)
        
        # éªŒè¯æŸå¤±å¯¹æ¯”
        ax3.plot(epochs, self.history['alexnet']['val_loss'], 'b-', label='AlexNet', linewidth=2)
        ax3.plot(epochs, self.history['lenet']['val_loss'], 'r-', label='LeNet', linewidth=2)
        ax3.set_title('éªŒè¯æŸå¤±å¯¹æ¯”')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Loss')
        ax3.legend()
        ax3.grid(True)
        
        # éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”
        ax4.plot(epochs, self.history['alexnet']['val_acc'], 'b-', label='AlexNet', linewidth=2)
        ax4.plot(epochs, self.history['lenet']['val_acc'], 'r-', label='LeNet', linewidth=2)
        ax4.set_title('éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”')
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('Accuracy')
        ax4.legend()
        ax4.grid(True)
        
        plt.tight_layout()
        plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')
        logger.info("å¯¹æ¯”å›¾å·²ä¿å­˜ä¸º model_comparison.png")
    
    def save_results(self):
        """ä¿å­˜ç»“æœ"""
        logger.info("ğŸ’¾ ä¿å­˜ç»“æœ...")
        
        results = {
            'final_results': self.final_results,
            'training_history': self.history,
            'model_info': {
                'alexnet': {
                    'parameters': self.alexnet.count_parameters(),
                    'size_mb': self.alexnet.get_model_size_mb()
                },
                'lenet': {
                    'parameters': self.lenet.count_parameters(),
                    'size_mb': self.lenet.get_model_size_mb()
                }
            }
        }
        
        with open('comparison_results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        
        logger.info("ç»“æœå·²ä¿å­˜ä¸º comparison_results.json")
    
    def print_summary(self):
        """æ‰“å°å¯¹æ¯”æ‘˜è¦"""
        print("\n" + "="*60)
        print("æ¨¡å‹å¯¹æ¯”æ‘˜è¦")
        print("="*60)
        
        print(f"{'æŒ‡æ ‡':<15} {'AlexNet':<15} {'LeNet':<15} {'å·®å¼‚':<15}")
        print("-" * 60)
        
        alexnet_acc = self.final_results['AlexNet']['final_accuracy']
        lenet_acc = self.final_results['LeNet']['final_accuracy']
        acc_diff = alexnet_acc - lenet_acc
        
        alexnet_time = self.final_results['AlexNet']['avg_inference_time']
        lenet_time = self.final_results['LeNet']['avg_inference_time']
        time_diff = lenet_time - alexnet_time
        
        alexnet_params = self.final_results['AlexNet']['model_params']
        lenet_params = self.final_results['LeNet']['model_params']
        params_ratio = alexnet_params / lenet_params
        
        print(f"{'æœ€ç»ˆå‡†ç¡®ç‡':<15} {alexnet_acc:.2%} {lenet_acc:.2%} {acc_diff:+.2%}")
        print(f"{'æ¨ç†æ—¶é—´(s)':<15} {alexnet_time:.4f} {lenet_time:.4f} {time_diff:+.4f}")
        print(f"{'å‚æ•°æ•°é‡':<15} {alexnet_params:,} {lenet_params:,} {params_ratio:.1f}x")
        
        print("\nç»“è®º:")
        if acc_diff > 0:
            print(f"âœ… AlexNetåœ¨å‡†ç¡®ç‡ä¸Šè¡¨ç°æ›´å¥½ (+{acc_diff:.2%})")
        else:
            print(f"âœ… LeNetåœ¨å‡†ç¡®ç‡ä¸Šè¡¨ç°æ›´å¥½ ({acc_diff:.2%})")
        
        if time_diff > 0:
            print(f"âœ… AlexNetæ¨ç†é€Ÿåº¦æ›´å¿« (-{time_diff:.4f}s)")
        else:
            print(f"âœ… LeNetæ¨ç†é€Ÿåº¦æ›´å¿« (+{abs(time_diff):.4f}s)")
        
        print(f"âœ… AlexNetå‚æ•°æ•°é‡æ˜¯LeNetçš„ {params_ratio:.1f} å€")
        print("="*60)

def main():
    """ä¸»å‡½æ•°"""
    try:
        # ç¡®ä¿åœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"MPSå¯ç”¨: {torch.backends.mps.is_available()}")
        
        # åˆ›å»ºå¯¹æ¯”å™¨å¹¶è¿è¡Œå¯¹æ¯”
        comparator = ModelComparison()
        comparator.compare_models()
        comparator.print_summary()
        
        print("\nğŸ‰ æ¨¡å‹å¯¹æ¯”å®Œæˆï¼")
        print("ğŸ“Š æŸ¥çœ‹ model_comparison.png è·å–å¯è§†åŒ–ç»“æœ")
        print("ğŸ“„ æŸ¥çœ‹ comparison_results.json è·å–è¯¦ç»†æ•°æ®")
        
    except ImportError as e:
        print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å·²æ¿€æ´»è™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…äº†æ‰€æœ‰ä¾èµ–")
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == '__main__':
    main()
